<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Less is More: Why Tiny Recursive Networks Beat Giant LLMs — Koushik Jaladi</title>
  <meta name="description" content="Here’s a counterintuitive result: a 7 million parameter model outperforms trillion-parameter LLMs on hard reasoning tasks. Not by a little—by a lot. On Sudok...">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Less is More: Why Tiny Recursive Networks Beat Giant LLMs | Koushik Jaladi</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Less is More: Why Tiny Recursive Networks Beat Giant LLMs" />
<meta name="author" content="Koushik Jaladi" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Here’s a counterintuitive result: a 7 million parameter model outperforms trillion-parameter LLMs on hard reasoning tasks. Not by a little—by a lot. On Sudoku-Extreme, the tiny model scores 87.4% while Claude, GPT-4, and DeepSeek score 0%." />
<meta property="og:description" content="Here’s a counterintuitive result: a 7 million parameter model outperforms trillion-parameter LLMs on hard reasoning tasks. Not by a little—by a lot. On Sudoku-Extreme, the tiny model scores 87.4% while Claude, GPT-4, and DeepSeek score 0%." />
<link rel="canonical" href="http://localhost:4001/tiny-recursive-models/" />
<meta property="og:url" content="http://localhost:4001/tiny-recursive-models/" />
<meta property="og:site_name" content="Koushik Jaladi" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-13T00:00:00+05:30" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Less is More: Why Tiny Recursive Networks Beat Giant LLMs" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Koushik Jaladi"},"dateModified":"2025-10-13T00:00:00+05:30","datePublished":"2025-10-13T00:00:00+05:30","description":"Here’s a counterintuitive result: a 7 million parameter model outperforms trillion-parameter LLMs on hard reasoning tasks. Not by a little—by a lot. On Sudoku-Extreme, the tiny model scores 87.4% while Claude, GPT-4, and DeepSeek score 0%.","headline":"Less is More: Why Tiny Recursive Networks Beat Giant LLMs","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4001/tiny-recursive-models/"},"url":"http://localhost:4001/tiny-recursive-models/"}</script>
<!-- End Jekyll SEO tag -->

  <link type="application/atom+xml" rel="alternate" href="http://localhost:4001/feed.xml" title="Koushik Jaladi" />

  <link rel="stylesheet" href="/assets/css/style.css">

  <!-- Preload critical font -->
  <link rel="preconnect" href="https://rsms.me/">
  <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
</head>
<body>

  <div class="frame">
    <header class="header">
  <a href="/" class="header__logo">
    Koushik Jaladi
  </a>

  <nav class="header__nav">
    <a href="/writing" >Writing</a>
    <a href="/about" >About</a>
    <a href="/now" >Now</a>
  </nav>
</header>


    <main class="main" role="main">
      <article class="article">
  <header class="article__header">
    <a href="/writing" class="article__back">← Writing</a>

    <div class="article__meta">
      <time datetime="2025-10-13T00:00:00+05:30">
        October 13, 2025
      </time>
      <span class="article__reading-time">
        5 min read
      </span>
    </div>

    <h1 class="article__title">Less is More: Why Tiny Recursive Networks Beat Giant LLMs</h1>

    
    <p class="article__subtitle">Exploring a research paper that challenges our assumptions about model scale</p>
    
  </header>

  <div class="article__content prose">
    <p>Here’s a counterintuitive result: a 7 million parameter model outperforms trillion-parameter LLMs on hard reasoning tasks. Not by a little—by a lot. On Sudoku-Extreme, the tiny model scores 87.4% while Claude, GPT-4, and DeepSeek score 0%.</p>

<p>How is this possible?</p>

<h2 id="the-trm-paper">The TRM Paper</h2>

<p>“Less is More: Recursive Reasoning with Tiny Networks” by Alexia Jolicoeur-Martineau presents the Tiny Recursive Model (TRM). The key insight: instead of making models bigger, make them think longer.</p>

<h2 id="the-architecture-depth-through-iteration">The Architecture: Depth Through Iteration</h2>

<p>TRM maintains two internal states:</p>

<ul>
  <li><strong>y</strong>: The current proposed answer (decodable)</li>
  <li><strong>z</strong>: A latent reasoning state (like chain-of-thought memory)</li>
</ul>

<p>The model iteratively refines both:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>For each step t:
    z ← f(x, y, z)    # Update reasoning based on problem + current answer
    y ← g(y, z)       # Update answer based on reasoning
</code></pre></div></div>

<p>This continues for up to 16 steps. The final y is the output.</p>

<p>Think of it like a human solving a puzzle: you make an initial guess, think about what’s wrong, update your guess, think more, update again. The model does this explicitly.</p>

<h2 id="why-shallow-networks-work">Why Shallow Networks Work</h2>

<p>Here’s the surprising finding: 2-layer networks with many iterations beat 8-layer networks with fewer iterations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Better: shallow + recursive
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">TRM</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>  <span class="c1"># 5M params, 87% accuracy
</span>
<span class="c1"># Worse: deep + single-pass
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">DeepNet</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 20M params, 45% accuracy
</span></code></pre></div></div>

<p>The hypothesis: deep networks overfit on small datasets. Shallow networks with explicit iteration are more constrained, forcing general reasoning strategies.</p>

<h2 id="data-augmentation-1000x-expansion">Data Augmentation: 1000x Expansion</h2>

<p>TRM trains on just 1,000 Sudoku examples—then augments to 1 million:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">augment_sudoku</span><span class="p">(</span><span class="n">puzzle</span><span class="p">,</span> <span class="n">solution</span><span class="p">):</span>
    <span class="n">augmented</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="c1"># Permute numbers (1↔3, 2↔7, etc.)
</span>        <span class="n">perm</span> <span class="o">=</span> <span class="nf">random_permutation</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">])</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="nf">apply_permutation</span><span class="p">(</span><span class="n">puzzle</span><span class="p">,</span> <span class="n">solution</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>

        <span class="c1"># Rotate/flip
</span>        <span class="n">p</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="nf">random_transform</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

        <span class="n">augmented</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">augmented</span>
</code></pre></div></div>

<p>The augmentations preserve Sudoku rules while creating novel instances. This is domain-aware augmentation—random pixel shuffling wouldn’t work.</p>

<h2 id="the-halting-mechanism">The Halting Mechanism</h2>

<p>When should the model stop iterating? TRM uses a simple binary classifier:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">should_halt</span><span class="p">(</span><span class="n">z</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="n">halt_prob</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">halt_head</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">halt_prob</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
</code></pre></div></div>

<p>If the model is confident in its answer, it stops early. Hard puzzles use more iterations. This is adaptive compute allocation without explicit training for it.</p>

<h2 id="results-that-challenge-assumptions">Results That Challenge Assumptions</h2>

<p>On ARC-AGI (a benchmark designed to test genuine reasoning):</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Parameters</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>TRM</td>
      <td>7M</td>
      <td>44.6%</td>
    </tr>
    <tr>
      <td>Gemini 2.5 Pro</td>
      <td>32B+</td>
      <td>37%</td>
    </tr>
    <tr>
      <td>DeepSeek R1</td>
      <td>671B</td>
      <td>~40%</td>
    </tr>
    <tr>
      <td>Grok-4</td>
      <td>1.7T</td>
      <td>66.7%</td>
    </tr>
  </tbody>
</table>

<p>TRM achieves competitive results with 0.01% of the parameters. It doesn’t beat everything, but it’s in the conversation.</p>

<p>On constrained reasoning (Sudoku-Extreme, Maze-Hard), TRM wins outright:</p>

<table>
  <thead>
    <tr>
      <th>Task</th>
      <th>TRM (7M)</th>
      <th>LLMs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sudoku-Extreme</td>
      <td>87.4%</td>
      <td>0%</td>
    </tr>
    <tr>
      <td>Maze-Hard</td>
      <td>85.3%</td>
      <td>0%</td>
    </tr>
  </tbody>
</table>

<p>Zero. Trillion-parameter models score zero on tasks a tiny recursive network handles easily.</p>

<h2 id="why-llms-fail-here">Why LLMs Fail Here</h2>

<p>Autoregressive generation is the wrong inductive bias for these tasks. LLMs generate tokens left-to-right; they can’t easily “go back” and revise earlier predictions based on later constraints.</p>

<p>Sudoku requires global constraint satisfaction. A digit placed in row 1 affects valid placements in row 9. Token-by-token generation doesn’t capture this structure.</p>

<p>TRM’s iterative refinement naturally handles global constraints. Each pass through the network can revise the entire answer based on full context.</p>

<h2 id="what-this-means">What This Means</h2>

<p><strong>Scale isn’t everything.</strong> For certain problem types, architectural inductive biases matter more than parameter counts.</p>

<p><strong>Iteration beats depth.</strong> Shallow networks with explicit reasoning loops can outperform deep networks that process in one pass.</p>

<p><strong>Domain matters.</strong> These results apply to constrained reasoning tasks. LLMs still win at open-ended language generation. The lesson isn’t “TRM is better” but “different architectures for different problems.”</p>

<h2 id="the-takeaway">The Takeaway</h2>

<p>We’ve assumed that general-purpose scaling is the path to artificial general intelligence. This paper suggests that specialized architectures with the right inductive biases can dramatically outperform at specific reasoning tasks.</p>

<p>Maybe the path to AGI isn’t one giant model, but a toolkit of specialized reasoners with different strengths.</p>

<hr />

<p><em>Exploring research that reminds us model architecture still matters in the era of scale.</em></p>

  </div>

  <footer class="article__footer">
    <div class="article__author">
      <p>Written by <strong>Koushik Jaladi</strong></p>
      <p class="article__author-links">
        <a href="https://twitter.com/koushikjaladi" target="_blank" rel="noopener">Twitter</a>
        <span>·</span>
        <a href="https://github.com/Koushik1161" target="_blank" rel="noopener">GitHub</a>
      </p>
    </div>
  </footer>
</article>



<section class="related">
  <p class="section__label">Continue Reading</p>
  <div class="posts">
    
    <article class="post-item post-item--compact">
      <a href="/isaac-groot/" class="post-item__link">
        <h3 class="post-item__title">GR00T: One Foundation Model for All Robots</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/mcp-quest-v2/" class="post-item__link">
        <h3 class="post-item__title">Teaching MCP Through an RPG: Metacon2</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/metacon-mcp-quest/" class="post-item__link">
        <h3 class="post-item__title">MCP Quest: Teaching Protocols Through Pokemon-Style RPGs</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/atlas-intelligence-dashboard/" class="post-item__link">
        <h3 class="post-item__title">3I/ATLAS Intelligence: Multi-Agent Astronomical Monitoring</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/1000-layer-networks-rl/" class="post-item__link">
        <h3 class="post-item__title">1000 Layers Deep: Scaling Networks for Self-Supervised RL</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/ramanujan-ucb/" class="post-item__link">
        <h3 class="post-item__title">When 100-Year-Old Math Beats Modern AI</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/bandit-ramanujan/" class="post-item__link">
        <h3 class="post-item__title">Ramanujan's Math Meets the Multi-Armed Bandit</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/gpt-researcher/" class="post-item__link">
        <h3 class="post-item__title">GPT Researcher: Autonomous Multi-Agent Research at Scale</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/cloid/" class="post-item__link">
        <h3 class="post-item__title">Cloid: A Voice-First Interview Bot</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/yolo-mask-conversion/" class="post-item__link">
        <h3 class="post-item__title">From SAM2 to YOLO: Bridging Segmentation and Detection</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/glenna-clarity/" class="post-item__link">
        <h3 class="post-item__title">Clarity: Making Academic Papers Actually Readable</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/gps-denied-navigation/" class="post-item__link">
        <h3 class="post-item__title">Navigating Without GPS: Visual Odometry from First Principles</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/echo-sanctuary/" class="post-item__link">
        <h3 class="post-item__title">Echo Sanctuary: Where AI Companions Have Real Conversations</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/prism-content-repurposing/" class="post-item__link">
        <h3 class="post-item__title">Prism: From One Blog Post to Six Platform Posts in Five Minutes</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/codec-quest-v2/" class="post-item__link">
        <h3 class="post-item__title">CODEC Quest: Gamifying Prompt Engineering Education</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/supermemory-landing-design/" class="post-item__link">
        <h3 class="post-item__title">Two Faces of Supermemory: Design Philosophy in Practice</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/codec-quest-ai-education/" class="post-item__link">
        <h3 class="post-item__title">CODEC QUEST: Teaching AI Literacy Through an 8-bit RPG</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/deepseek-ocr/" class="post-item__link">
        <h3 class="post-item__title">DeepSeek-OCR: Compressing Documents for the Age of Context Windows</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/dew-breathing-app/" class="post-item__link">
        <h3 class="post-item__title">Dew: Neo-Brutalist Breathing Meditation for iOS</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/chimera-ace-architecture/" class="post-item__link">
        <h3 class="post-item__title">Chimera: Building Agents That Actually Think</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/whitestellar-agents-sdk/" class="post-item__link">
        <h3 class="post-item__title">WhiteStellar: Learning the OpenAI Agents SDK from First Principles</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/project-maxion/" class="post-item__link">
        <h3 class="post-item__title">Project Maxion: The Self-Healing Agentic Browser</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/supermemory-landing-pages/" class="post-item__link">
        <h3 class="post-item__title">Two Faces of Product Design: Supermemory Landing Pages</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/whatsapp-copilot/" class="post-item__link">
        <h3 class="post-item__title">Building a WhatsApp Sales Copilot</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/metacon3-neon-prompt-builder/" class="post-item__link">
        <h3 class="post-item__title">NEON: A Gamified CLI for Prompt Engineering</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/sakana-model-merging/" class="post-item__link">
        <h3 class="post-item__title">Merging Intelligence: Combining Qwen and DeepSeek with SLERP</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/agentic-ai-research-hub/" class="post-item__link">
        <h3 class="post-item__title">Interactive Research Hub: Visualizing the AI Agent Landscape</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/agentic-ai-2025-hub/" class="post-item__link">
        <h3 class="post-item__title">Agentic AI 2025: An Interactive Research Visualization</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/geon-interview-ai/" class="post-item__link">
        <h3 class="post-item__title">Geon: Building an AI Interviewer That Actually Cares</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/breezeblow-landing-pages/" class="post-item__link">
        <h3 class="post-item__title">Testio: Multi-Theme Landing Page Exploration</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/zorever-chatbot/" class="post-item__link">
        <h3 class="post-item__title">Building a Real Estate Chatbot That Actually Works</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/ai-enhanced-pdf-analyzer/" class="post-item__link">
        <h3 class="post-item__title">Building a Seriously Smart PDF Analyzer</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/repour-content-repurposing/" class="post-item__link">
        <h3 class="post-item__title">Repour: Multi-Agent Content Repurposing</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/awesome-claude-code-subagents/" class="post-item__link">
        <h3 class="post-item__title">116 Specialized Agents for Claude Code</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/magentic-ui/" class="post-item__link">
        <h3 class="post-item__title">Human-Centered Web Automation with Magentic-UI</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/godfather-ai-news/" class="post-item__link">
        <h3 class="post-item__title">Godfather: AI-Powered News Aggregation</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/vibe-decode/" class="post-item__link">
        <h3 class="post-item__title">VibeDecode: Understanding Your Instagram Aesthetic with AI</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/agent-zx/" class="post-item__link">
        <h3 class="post-item__title">Agent ZX: Building an Autonomous Web Browser</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/project-maverick/" class="post-item__link">
        <h3 class="post-item__title">Project Maverick: From Prompt to Production App in Days</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/pdf-intelligence/" class="post-item__link">
        <h3 class="post-item__title">PDF Intelligence: Extracting Meaning from Documents</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/doc-ai-analyzer/" class="post-item__link">
        <h3 class="post-item__title">Building a Production-Ready Document Analysis Platform</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/compress-chat-ocr-demo/" class="post-item__link">
        <h3 class="post-item__title">CompressChatOCR: 10x Token Reduction for Document AI</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/ai-doc-pro/" class="post-item__link">
        <h3 class="post-item__title">AI Doc Pro: Minimal Document Analysis</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/compress-chat-ocr/" class="post-item__link">
        <h3 class="post-item__title">10x Token Compression: Vision-Based Document Processing</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/calorie-tracker-ios/" class="post-item__link">
        <h3 class="post-item__title">Starting an iOS Project: CalorieTracker Foundation</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/project-dis-document-analyzer/" class="post-item__link">
        <h3 class="post-item__title">Two Paths to Document Analysis: Local vs Cloud</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/project-delta-landing-generator/" class="post-item__link">
        <h3 class="post-item__title">AI Landing Page Generator: From Prompt to Preview</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/uniq-ramanujan-ucb/" class="post-item__link">
        <h3 class="post-item__title">Uniq: When Ramanujan's Math Meets Game AI</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/frijan-voice-assistant/" class="post-item__link">
        <h3 class="post-item__title">FRIJAN: Voice-First AI Assistant Architecture</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/vortex-deep-research/" class="post-item__link">
        <h3 class="post-item__title">Vortex: Deep Research with Iterative Refinement</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/rl-adventure-learning/" class="post-item__link">
        <h3 class="post-item__title">Learning Reinforcement Learning Through Play</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/research-swarm/" class="post-item__link">
        <h3 class="post-item__title">Research Swarm: Multi-Agent Research That Actually Works</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/damac-finance-agents/" class="post-item__link">
        <h3 class="post-item__title">DAMAC Finance AI: Enterprise Multi-Agent Automation</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/cloid-clean-voice-bot/" class="post-item__link">
        <h3 class="post-item__title">The Siri-Style Voice Bot: Real-Time Conversations with OpenAI</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/damac-finance-ai/" class="post-item__link">
        <h3 class="post-item__title">Building Enterprise-Grade Multi-Agent Finance AI</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/seecal-ai/" class="post-item__link">
        <h3 class="post-item__title">SeeCal AI: Point, Shoot, Know What You're Eating</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/lumina-ai-chat/" class="post-item__link">
        <h3 class="post-item__title">Lumina: A Clean Slate for AI Chat Interfaces</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/phantomcore-shell/" class="post-item__link">
        <h3 class="post-item__title">PhantomCore Shell: AI Meets the Desktop</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/personaforge/" class="post-item__link">
        <h3 class="post-item__title">PersonaForge: A Backend for AI Characters</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/xelora/" class="post-item__link">
        <h3 class="post-item__title">Xelora: A Local-First Research Agent</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/sentinel-ai/" class="post-item__link">
        <h3 class="post-item__title">Sentinel AI: Building an Autonomous Research Agent</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/doppel-agent/" class="post-item__link">
        <h3 class="post-item__title">DoppelAgent: When Two AIs Are Better Than One</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/gemini-agentic-research-assistant/" class="post-item__link">
        <h3 class="post-item__title">Building a Multi-Model Research Assistant</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/aetherdraft/" class="post-item__link">
        <h3 class="post-item__title">Aetherdraft: Teaching AI to Write Better Emails</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/openai-agents-sdk-intro/" class="post-item__link">
        <h3 class="post-item__title">Getting Started with OpenAI's Agents SDK</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/grid-world-agents/" class="post-item__link">
        <h3 class="post-item__title">Grid World Agents: Multi-Agent Simulation Basics</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/less-but-better/" class="post-item__link">
        <h3 class="post-item__title">Less, But Better</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/the-reliability-gap/" class="post-item__link">
        <h3 class="post-item__title">The Reliability Gap</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/thinking-in-systems/" class="post-item__link">
        <h3 class="post-item__title">Thinking in Systems</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/on-simplicity/" class="post-item__link">
        <h3 class="post-item__title">On Simplicity</h3>
      </a>
    </article>
    
    <article class="post-item post-item--compact">
      <a href="/tools-and-thought/" class="post-item__link">
        <h3 class="post-item__title">Tools and Thought</h3>
      </a>
    </article>
    
  </div>
</section>


    </main>

    <footer class="footer">
  <div class="footer__content">
    <p class="footer__colophon">
      <span class="footer__year">2026</span>
      <span class="footer__sep">·</span>
      <span class="footer__name">Koushik Jaladi</span>
    </p>
    <div class="footer__links">
      <a href="https://twitter.com/koushikjaladi" target="_blank" rel="noopener">Twitter</a>
      <a href="https://github.com/Koushik1161" target="_blank" rel="noopener">GitHub</a>
      <a href="/feed.xml">RSS</a>
    </div>
  </div>
</footer>

  </div>

  <script src="/assets/js/main.js" defer></script>
</body>
</html>
