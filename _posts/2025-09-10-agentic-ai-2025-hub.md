---
layout: post
title: "Agentic AI 2025: An Interactive Research Visualization"
subtitle: "Building a data-driven exploration of the AI agent framework landscape"
date: 2025-09-10
---

The AI agent ecosystem exploded in 2024-2025. OpenAI launched their Agents SDK. Anthropic introduced the Model Context Protocol. Google shipped Vertex AI with ADK. Microsoft entered with their Agent Framework. LangChain, CrewAI, and AutoGPT continued evolving.

Keeping track of it all was impossible. So I built an interactive research hub to visualize the landscape.

## Five Ways to Explore

The visualization offers five distinct interaction modes, each suited for different learning styles:

**Galaxy View** renders frameworks as nodes in a 3D-style network. Eight frameworks orbit a central hub, connected by relationship lines. Click any node to see details: launch date, GitHub stars, category classification. Auto-rotation gives a passive overview; zoom controls let you dive deep.

**Battle Mode** enables head-to-head comparison. Select two frameworks from dropdowns, and they face off in a visual arena. Side-by-side specs, strengths, weaknesses. It's gamified but genuinely useful for decision-making.

**Journey Mode** presents a horizontal scrolling timeline through five scenes: Market Explosion, Protocol Revolution, Architecture Patterns, Enterprise Adoption, Future Trajectory. Arrow keys or buttons navigate. Each scene combines narrative with data visualizations—growth charts, adoption curves, architectural diagrams.

**Terminal Mode** provides a command-line interface. Type `list` for frameworks, `compare openai anthropic` for matchups, `stats` for market data. It's faster than clicking for power users who prefer keyboards.

**Dashboard Mode** displays analytics: counters animating to final values, radar charts comparing framework attributes, ranking lists, heat maps, timeline scrubbers projecting through 2030.

## The Data Story

The visualization tells a specific narrative about agentic AI in 2025:

**Market explosion**: $48.2B projected by 2030, 920% repository growth, 72% organizational adoption.

**Protocol convergence**: Two standards emerging—MCP (Model Context Protocol) for tool connectivity, A2A (Agent-to-Agent) for inter-agent communication.

**Architecture patterns**: ReAct, Sequential, Multi-Agent, and Orchestrator patterns dominating production deployments.

**Enterprise adoption**: 45% of Fortune 500 companies running pilots, projected 87% by 2030.

These aren't made-up numbers—they're synthesized from industry reports, GitHub statistics, and analyst projections.

## Technical Implementation

The entire application is vanilla JavaScript—no React, no Vue, no build process. Three files: HTML structure, JavaScript logic, CSS styling. About 2,200 lines total.

**Canvas-based rendering** handles both the particle background (100 animated particles with distance-based connections) and the galaxy network visualization. RequestAnimationFrame ensures smooth 60fps animation.

**CSS animations** manage the cyberpunk aesthetic: neon glows, pulsing effects, orbital movements, fade-in reveals. Keyframe animations avoid JavaScript overhead for decorative motion.

**Web Audio API** generates sound effects procedurally—no audio files, just oscillators with frequency modulation. Clicks beep, transitions whoosh, all synthesized in real-time.

**Command palette** (Cmd/Ctrl+K) provides keyboard-driven navigation. Type framework names for instant search, execute commands for direct action.

## Design Language

The aesthetic is deliberately cyberpunk: neon cyan and hot pink against dark backgrounds, glass morphism panels with backdrop blur, grid patterns suggesting digital infrastructure.

This isn't arbitrary style—it communicates "cutting edge" and "technical depth." A minimalist white design might feel more professional but less exciting. The audience for this content expects visual energy.

Typography uses system fonts for speed (Inter, JetBrains Mono, Space Grotesk via Google Fonts). The hierarchy is clear: massive headlines for section titles, medium text for content, monospace for terminal and code.

## Interactive Patterns

Every section responds to user input:

**Galaxy nodes** detect clicks through distance calculation from click coordinates to node centers. Selected nodes highlight; detail panels slide in.

**Journey scenes** respond to keyboard (arrow keys), clicks (navigation buttons), and scroll (horizontal scrub). Progress bars track position visually.

**Terminal** parses command strings, maintains history, and outputs formatted responses. It's a genuine (if simple) command interpreter.

**Dashboard counters** animate from zero to final values on viewport entry, creating that satisfying "data loading" effect.

## What I Learned

**Data visualization is storytelling**. The same numbers arranged differently tell different stories. I chose narrative arc over neutral presentation—the visualization has a thesis about where agentic AI is heading.

**Vanilla JavaScript remains capable**. No framework was necessary for this complexity level. Canvas, CSS animations, and DOM manipulation handled everything. The benefit: zero dependencies, instant load, portable HTML file.

**Sound matters**. The audio toggle exists because sound genuinely enhances the experience—clicks feel responsive, transitions feel smooth. But opt-in respects user preferences.

**Multiple interaction modalities serve different users**. Galaxy appeals to visual learners. Terminal appeals to power users. Journey appeals to narrative thinkers. Dashboard appeals to data analysts. Same content, multiple paths.

**Forward-dating content requires careful sourcing**. The visualization references October 2025 launches—this required extrapolating from announced roadmaps and industry trends. Speculation is labeled as projection, not fact.

The AI agent landscape will continue evolving. The visualization framework can evolve with it—new nodes in the galaxy, new scenes in the journey, new commands in the terminal. The structure scales; the content updates.
