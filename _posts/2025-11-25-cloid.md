---
layout: post
title: "Cloid: A Voice-First Interview Bot"
subtitle: "Building real-time voice AI with WebRTC and OpenAI's Realtime API"
date: 2025-11-25
---

There's something text interfaces miss: the way someone pauses before answering, the enthusiasm in their voice, the natural flow of conversation. When I set out to build an AI assessment tool, I knew it had to be voice-first.

Cloid is a real-time voice interview bot that lets candidates respond to questions in their own voice, capturing authenticity that typed responses can't match.

## The Technical Challenge: Low Latency is Everything

Voice conversation requires sub-second latency. Any delay feels unnatural, breaks the conversational flow, and frustrates users. This ruled out the typical approach of recording audio, sending it to a server, transcribing, generating a response, and synthesizing speech.

Instead, I built on OpenAI's Realtime API with WebRTC:

```javascript
async function connect() {
    // Get ephemeral token from our server
    const tokenResponse = await fetch('/session');
    const { token } = await tokenResponse.json();

    // Connect directly to OpenAI via WebRTC
    const pc = new RTCPeerConnection();
    const dc = pc.createDataChannel('response');

    // Stream user audio directly
    const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
        }
    });

    stream.getTracks().forEach(track => pc.addTrack(track, stream));
    // ... SDP negotiation with OpenAI
}
```

The key is that audio streams directly between the browser and OpenAI. Our server only handles initial authentication, never touching the audio itself. This keeps latency minimal.

## The Security Model: Ephemeral Tokens

Never expose API keys to browsers. Instead, the server generates short-lived tokens:

```javascript
// server.js
app.get('/session', async (req, res) => {
    const response = await fetch('https://api.openai.com/v1/realtime/sessions', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model: 'gpt-4o-realtime-preview',
            voice: 'echo'
        })
    });

    const { client_secret } = await response.json();
    res.json({ token: client_secret.value });
});
```

The token is valid for one session. Even if intercepted, it can't be reused for other purposes. The actual API key never leaves the server.

## Personalization: The Interview Context

What makes Cloid an interview bot rather than a generic voice assistant? The system prompt:

```javascript
const personalInfo = {
    name: "Alex",
    lifeStory: "Grew up in a small town, discovered coding at 14...",
    superpowers: ["Deep technical knowledge", "Clear communication"],
    growthAreas: ["Public speaking", "Delegation"],
    misconceptions: ["People think I'm an introvert..."]
};

const systemInstructions = `
You are ${personalInfo.name}, responding to interview questions.
Speak naturally, in first person, as yourself.

Your background: ${personalInfo.lifeStory}
Your strengths: ${personalInfo.superpowers.join(', ')}
Areas you're developing: ${personalInfo.growthAreas.join(', ')}

IMPORTANT: Only answer questions related to the interview.
If asked trivia, math, or off-topic questions, politely redirect.
`;
```

The AI responds as the candidate, drawing on their specific background. This creates personalized interview practice or assessment scenarios.

## The Interface: Jony Ive Would Approve

I obsessed over the UI. An interview should feel calm, focused, professional. Not cluttered with controls and stats.

The centerpiece is an orb—a gradient sphere that breathes and pulses based on conversation state:

```css
.orb {
    background: radial-gradient(circle at 30% 30%,
        rgba(255, 255, 255, 0.4),
        rgba(79, 70, 229, 0.8),
        rgba(17, 24, 39, 0.95)
    );
    animation: breathe 4s ease-in-out infinite;
}

@keyframes breathe {
    0%, 100% { transform: scale(1); opacity: 0.8; }
    50% { transform: scale(1.05); opacity: 1; }
}
```

When listening, the orb glows softly. When the AI speaks, it pulses with the audio. When processing, it shimmers. No text labels needed—the orb's behavior communicates state.

## Real-Time Transcription

For accessibility and record-keeping, conversations are transcribed live:

```javascript
dc.addEventListener('message', (event) => {
    const data = JSON.parse(event.data);

    if (data.type === 'response.audio_transcript.delta') {
        appendToTranscript('AI', data.delta);
    }

    if (data.type === 'conversation.item.input_audio_transcription') {
        appendToTranscript('User', data.transcript);
    }
});
```

The transcript appears in a subtle side panel—visible if you want it, ignorable if you don't.

## Voice Activity Detection

Getting speech boundaries right is crucial. I use server-side VAD (Voice Activity Detection):

```javascript
sessionConfig: {
    turn_detection: {
        type: "server_vad",
        threshold: 0.5,
        prefix_padding_ms: 300,
        silence_duration_ms: 500
    }
}
```

The server detects when the user stops speaking and automatically triggers a response. The 500ms silence threshold balances responsiveness against cutting people off mid-thought.

## Scope Enforcement: Staying On Topic

An interview bot shouldn't answer trivia questions. The system prompt explicitly restricts scope:

```
If asked questions outside the interview context—math problems,
general knowledge, coding challenges, etc.—politely decline and
redirect: "I'm here to discuss my background and qualifications.
What would you like to know about my experience?"
```

This keeps the AI in character and prevents misuse as a general assistant.

## What I Learned

**WebRTC is powerful but complex.** SDP negotiation, ICE candidates, track management—there's a lot to get right. But the payoff is true real-time streaming that HTTP can't match.

**Design is part of the product.** The breathing orb isn't decoration. It provides feedback, sets the tone, and makes the experience feel alive. Every animation is intentional.

**Constraints create focus.** By limiting the AI to interview topics, I made it better at those topics. Scope enforcement isn't limitation—it's focus.

---

*Built with WebRTC, OpenAI's Realtime API, and a conviction that the best interfaces disappear into the experience.*
